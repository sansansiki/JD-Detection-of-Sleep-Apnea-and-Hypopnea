{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用机器学习抽取信号特征的时序分类方法\n",
    "\n",
    "### 1.特征抽取\n",
    "\n",
    "### 2.特征选择\n",
    "\n",
    "### 3.model stacking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from processing_utils import *\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore',invalid='ignore')\n",
    "import _pickle as pkl\n",
    "def load_file_with_p(file_path):\n",
    "    '''载入,p二进制文件'''\n",
    "    return pkl.load(open(file_path,'rb'))\n",
    "\n",
    "def save_file_with_p(save_df,file_path):\n",
    "    '''载入,p二进制文件'''\n",
    "    pkl.dump(save_df,open(file_path,'wb'))\n",
    "\n",
    "def remove_highly_correlated_columns(df, threshold):\n",
    "    # 计算相关系数矩阵\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    # 创建一个布尔值的DataFrame，表示相关系数是否大于阈值\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool_))\n",
    "\n",
    "    # 获取要删除的列名\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    print(to_drop)\n",
    "    # 删除相关系数较高的列\n",
    "    df = df.drop(to_drop, axis=1)\n",
    "\n",
    "    return df,to_drop,upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "train_X = np.load('训练集/train_x.npy') \n",
    "train_y = np.load('训练集/train_y.npy') \n",
    "\n",
    "\n",
    "test_X = np.load('测试集A/test_x_A.npy')\n",
    "df_test_y = pd.read_csv('测试集A/submit_example_A.csv')\n",
    "\n",
    "df = pd.DataFrame(columns=['id','time','f1','f2'])\n",
    "\n",
    "for index,i in enumerate(test_X):\n",
    "    tdf = pd.DataFrame(i).T\n",
    "    tdf.columns = ['f1','f2']\n",
    "    tdf['id'] = index\n",
    "    tdf['time'] = [j for j in range(len(tdf))]\n",
    "    \n",
    "    tdf = tdf[['id','time','f1','f2']]\n",
    "    df = pd.concat([df,tdf])\n",
    "\n",
    "\n",
    "df.to_csv('/home/gsl/workspace/jd/data/test.csv',index=False)\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('/train_1.csv')\n",
    "df2 = pd.read_csv('/train_2.csv')\n",
    "df_test = pd.read_csv(/test.csv')\n",
    "df2['id'] = df2['id'] + 15000\n",
    "df = pd.concat([df1,df2])\n",
    "\n",
    "extracted_features = extract_features(df, column_id=\"id\", column_sort=\"time\")\n",
    "extracted_features_test = extract_features(df_test, column_id=\"id\", column_sort=\"time\")\n",
    "\n",
    "impute(extracted_features)\n",
    "features_filtered = select_features(extracted_features, train_y)\n",
    "impute(extracted_features_test)\n",
    "features_filtered_test = extracted_features_test[features_filtered.columns.tolist()]\n",
    "\n",
    "save_file_with_p(features_filtered,'/train.p')\n",
    "save_file_with_p(features_filtered_test,'/test.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_filtered = load_file_with_p(/train.p')\n",
    "features_filtered_test = load_file_with_p('/test.p')\n",
    "y_train = np.load('train_y.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29808\n",
       "2     4520\n",
       "1     3221\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提升方式：\n",
    "\n",
    "特征优化\n",
    "模型融合\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.特征优化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.去除冗余特征\n",
    "\n",
    "# x_train,to_drop,upper = remove_highly_correlated_columns(features_filtered,threshold=0.7)\n",
    "# x_test = features_filtered_test[x_train.columns.tolist()]\n",
    "\n",
    "x_train = features_filtered\n",
    "x_test = features_filtered_test\n",
    "\n",
    "# 2.修改特征列名\n",
    "source_cols = x_train.columns.tolist()\n",
    "x_train.columns = [f'fea_{i}' for i in range(len(source_cols))]\n",
    "x_test.columns = [f'fea_{i}' for i in range(len(source_cols))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.模型融合\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 0.239915\tvalid_1's multi_logloss: 0.375426\n",
      "[0.8605858854860187]\n",
      "************************************ 2 ************************************\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's multi_logloss: 0.254084\tvalid_1's multi_logloss: 0.370691\n",
      "[0.8605858854860187, 0.8628495339547271]\n",
      "************************************ 3 ************************************\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's multi_logloss: 0.22103\tvalid_1's multi_logloss: 0.385156\n",
      "[0.8605858854860187, 0.8628495339547271, 0.8541944074567244]\n",
      "************************************ 4 ************************************\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's multi_logloss: 0.255355\tvalid_1's multi_logloss: 0.365088\n",
      "[0.8605858854860187, 0.8628495339547271, 0.8541944074567244, 0.8613848202396804]\n",
      "************************************ 5 ************************************\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's multi_logloss: 0.232894\tvalid_1's multi_logloss: 0.367539\n",
      "[0.8605858854860187, 0.8628495339547271, 0.8541944074567244, 0.8613848202396804, 0.8624317485683846]\n",
      "************************************ 1 ************************************\n",
      "[0.8659121171770972]\n",
      "************************************ 2 ************************************\n",
      "[0.8659121171770972, 0.8645805592543275]\n",
      "************************************ 3 ************************************\n",
      "[0.8659121171770972, 0.8645805592543275, 0.8569906790945406]\n",
      "************************************ 4 ************************************\n",
      "[0.8659121171770972, 0.8645805592543275, 0.8569906790945406, 0.8624500665778961]\n",
      "************************************ 5 ************************************\n",
      "[0.8659121171770972, 0.8645805592543275, 0.8569906790945406, 0.8624500665778961, 0.8650952190704488]\n",
      "************************************ 1 ************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7307551\ttest: 0.7328018\tbest: 0.7328018 (0)\ttotal: 104ms\tremaining: 3m 26s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.3721735634\n",
      "bestIteration = 116\n",
      "\n",
      "Shrink model to first 117 iterations.\n",
      "[0.8607190412782956]\n",
      "************************************ 2 ************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7306870\ttest: 0.7291676\tbest: 0.7291676 (0)\ttotal: 97.6ms\tremaining: 3m 15s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.3656341428\n",
      "bestIteration = 127\n",
      "\n",
      "Shrink model to first 128 iterations.\n",
      "[0.8607190412782956, 0.8607190412782956]\n",
      "************************************ 3 ************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7339951\ttest: 0.7375335\tbest: 0.7375335 (0)\ttotal: 99.4ms\tremaining: 3m 18s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.3741820356\n",
      "bestIteration = 126\n",
      "\n",
      "Shrink model to first 127 iterations.\n",
      "[0.8607190412782956, 0.8607190412782956, 0.859121171770972]\n",
      "************************************ 4 ************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7328815\ttest: 0.7319509\tbest: 0.7319509 (0)\ttotal: 101ms\tremaining: 3m 21s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.3597586346\n",
      "bestIteration = 78\n",
      "\n",
      "Shrink model to first 79 iterations.\n",
      "[0.8607190412782956, 0.8607190412782956, 0.859121171770972, 0.8617842876165113]\n",
      "************************************ 5 ************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7306804\ttest: 0.7296355\tbest: 0.7296355 (0)\ttotal: 97.5ms\tremaining: 3m 14s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.3613000029\n",
      "bestIteration = 108\n",
      "\n",
      "Shrink model to first 109 iterations.\n",
      "[0.8607190412782956, 0.8607190412782956, 0.859121171770972, 0.8617842876165113, 0.8634971367692102]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score  \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def cv_model(clf, train_x, train_y, test_x, clf_name, seed = 2023):\n",
    "    folds = 5\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    num_class = 3 \n",
    "    oof = np.zeros((train_x.shape[0], num_class))  # 适应三分类\n",
    "    test_predict = np.zeros((test_x.shape[0], num_class))  # 适应三分类\n",
    "    cv_scores = []\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "        \n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'multiclass',\n",
    "                'min_child_weight': 6,\n",
    "                'num_leaves': 2 ** 6,\n",
    "                'lambda_l2': 10,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'bagging_freq': 4,\n",
    "                'learning_rate': 0.35,\n",
    "                'seed': 2024,\n",
    "                'nthread' : 16,\n",
    "                'verbose' : -1,\n",
    "                'num_class':num_class\n",
    "            }\n",
    "            model = clf.train(params, train_matrix, 2000, valid_sets=[train_matrix, valid_matrix],\n",
    "                              categorical_feature=[], verbose_eval=1000, early_stopping_rounds=100)\n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "        \n",
    "        if clf_name == \"xgb\":\n",
    "\n",
    "            xgbc = XGBClassifier(reg_lambda = 9.0,\n",
    "                            reg_alpha = 2.93,\n",
    "                            gamma=5,\n",
    "                            max_depth=15,\n",
    "                            colsample_bytree = 0.6,\n",
    "                            subsample = 0.7,\n",
    "                            learning_rate = 0.35,\n",
    "                            n_estimators = 60,\n",
    "                            min_child_weight = 7,\n",
    "                            objective='multi:softmax',\n",
    "                            n_jobs=12)\n",
    "            \n",
    "            # model = clf.train(xgbc, train_matrix, num_boost_round=2000, evals=watchlist, verbose_eval=1000, early_stopping_rounds=100)\n",
    "            xgbc.fit(trn_x,trn_y)\n",
    "            val_pred  = xgbc.predict_proba(val_x)\n",
    "            test_pred = xgbc.predict_proba(test_x)\n",
    "\n",
    "        if clf_name == \"cat\":\n",
    "            params = {'learning_rate': 0.35, 'depth': 5, 'bootstrap_type':'Bernoulli','random_seed':2024,\n",
    "                      'od_type': 'Iter', 'od_wait': 100, 'random_seed': 11, 'allow_writing_files': False,\n",
    "                      'loss_function':'MultiClass'}\n",
    "            \n",
    "            model = clf(iterations=2000, **params)\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      metric_period=1000,\n",
    "                      use_best_model=True, \n",
    "                      cat_features=[],\n",
    "                      verbose=1)\n",
    "            \n",
    "            val_pred  = model.predict_proba(val_x)\n",
    "            test_pred = model.predict_proba(test_x)\n",
    "        \n",
    "        oof[valid_index] = val_pred\n",
    "        test_predict += test_pred / kf.n_splits\n",
    "        \n",
    "        F1_score = accuracy_score(val_y, np.argmax(val_pred, axis=1))  # 适应三分类\n",
    "        cv_scores.append(F1_score)\n",
    "        print(cv_scores)\n",
    "        \n",
    "    return oof, test_predict\n",
    "\n",
    "# 参考demo,具体对照baseline实践部分调用cv_model函数\n",
    "# 选择lightgbm模型\n",
    "lgb_oof, lgb_test = cv_model(lgb, x_train, y_train, x_test, 'lgb')\n",
    "# 选择xgboost模型\n",
    "xgb_oof, xgb_test = cv_model(xgb, x_train, y_train, x_test, 'xgb')\n",
    "# 选择catboost模型\n",
    "cat_oof, cat_test = cv_model(CatBoostClassifier, x_train, y_train, x_test, 'cat')\n",
    "\n",
    "# # 进行取平均融合\n",
    "# final_test = (lgb_test + xgb_test + cat_test) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取预测标签\n",
    "lgb_df = pd.DataFrame(np.argmax(lgb_oof,axis=1),columns=['lgb'])\n",
    "xgb_df = pd.DataFrame(np.argmax(xgb_oof,axis=1),columns=['xgb'])\n",
    "cat_df = pd.DataFrame(np.argmax(cat_oof,axis=1),columns=['cat'])\n",
    "\n",
    "lgb_test_df = pd.DataFrame(np.argmax(lgb_test,axis=1),columns=['lgb'])\n",
    "xgb_test_df = pd.DataFrame(np.argmax(xgb_test,axis=1),columns=['xgb'])\n",
    "cat_test_df = pd.DataFrame(np.argmax(cat_test,axis=1),columns=['cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    791\n",
      "1    232\n",
      "2    132\n",
      "Name: lgb, dtype: int64\n",
      "0    779\n",
      "1    245\n",
      "2    131\n",
      "Name: xgb, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    790\n",
       "1    238\n",
       "2    127\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lgb_test_df['lgb'].value_counts())\n",
    "print(xgb_test_df['xgb'].value_counts())\n",
    "cat_test_df['cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "1/5 0.8624500665778961\n",
      "fold n°2\n",
      "2/5 0.8588548601864181\n",
      "fold n°3\n",
      "3/5 0.8668442077230359\n",
      "fold n°4\n",
      "4/5 0.8693741677762983\n",
      "fold n°5\n",
      "5/5 0.8653615661206552\n",
      "fold n°6\n",
      "6/5 0.8653794940079893\n",
      "fold n°7\n",
      "7/5 0.8655126498002663\n",
      "fold n°8\n",
      "8/5 0.863115845539281\n",
      "fold n°9\n",
      "9/5 0.8617842876165113\n",
      "fold n°10\n",
      "10/5 0.8630976161939007\n",
      "mean:  0.8641774761542251\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "\n",
    "\n",
    "def stack_model(oof_1, oof_2, oof_3, predictions_1, predictions_2, predictions_3, y):\n",
    "    '''\n",
    "    输入的oof_1, oof_2, oof_3可以对应lgb_oof，xgb_oof，cat_oof\n",
    "    predictions_1, predictions_2, predictions_3对应lgb_test，xgb_test，cat_test\n",
    "    '''\n",
    "    train_stack = pd.concat([oof_1, oof_2, oof_3], axis=1)\n",
    "    test_stack = pd.concat([predictions_1, predictions_2, predictions_3], axis=1)\n",
    "    \n",
    "    oof = np.zeros((train_stack.shape[0],))\n",
    "    predictions = np.zeros((test_stack.shape[0],))\n",
    "    scores = []\n",
    "    \n",
    "    from sklearn.model_selection import RepeatedKFold\n",
    "    folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=2021)\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_stack, train_stack)): \n",
    "        print(\"fold n°{}\".format(fold_+1))\n",
    "        trn_data, trn_y = train_stack.loc[trn_idx], y[trn_idx]\n",
    "        val_data, val_y = train_stack.loc[val_idx], y[val_idx]\n",
    "        \n",
    "        clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "        clf.fit(trn_data, trn_y)\n",
    "\n",
    "        oof[val_idx] = clf.predict(val_data)\n",
    "        predictions += clf.predict(test_stack) / (5 * 2)\n",
    "\n",
    "        score_single = accuracy_score(val_y, oof[val_idx])\n",
    "        scores.append(score_single)\n",
    "        print(f'{fold_+1}/{5}', score_single)\n",
    "    print('mean: ',np.mean(scores))\n",
    "   \n",
    "    return oof, predictions\n",
    "\n",
    "\n",
    "oof, predictions = stack_model(lgb_df,xgb_df,cat_df,lgb_test_df,xgb_test_df,cat_test_df,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(predictions,columns=['label'])\n",
    "res_df['id'] = res_df.index\n",
    "res_df = res_df[['id','label']]\n",
    "res_df['label'] = res_df['label'].round().astype(int)\n",
    "res_df.to_csv('submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    789\n",
       "1    256\n",
       "2    110\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt_wide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
